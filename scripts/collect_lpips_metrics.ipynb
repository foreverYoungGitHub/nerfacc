{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc938528-88c5-4d71-8874-16aa465595fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462c3b2a-1601-485a-bf78-52e69fec8636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hangg/.anaconda3/envs/nerfacc/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import warnings\n",
    "from glob import glob\n",
    "from typing import Callable, Literal, Optional\n",
    "\n",
    "import cv2\n",
    "import lpips\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce94c04-1c2b-4052-9657-9729c88f6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPIPS_MODELS = {\"alex\": None, \"vgg\": None}\n",
    "\n",
    "\n",
    "def get_compute_lpips(\n",
    "    net: Literal[\"alex\", \"vgg\"] = \"vgg\", device: str = \"cuda\"\n",
    ") -> Callable:\n",
    "    \"\"\"Get the LPIPS metric function as a singleton to avoid extra copy.\"\"\"\n",
    "\n",
    "    global LPIPS_MODELS\n",
    "    if LPIPS_MODELS[net] is None:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            LPIPS_MODELS[net] = lpips.LPIPS(net=net, spatial=True).to(device)\n",
    "    model = LPIPS_MODELS[net]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def compute_lpips(\n",
    "        img0: torch.Tensor,\n",
    "        img1: torch.Tensor,\n",
    "    ) -> np.array:\n",
    "        \"\"\"Compute LPIPS between two images.\n",
    "\n",
    "        Args:\n",
    "            img0: (H, W, 3) in uint8.\n",
    "            img1: (H, W, 3).\n",
    "\n",
    "        Returns:\n",
    "            lpips: (), LPIPS score in [0, 1].\n",
    "        \"\"\"\n",
    "        img0 = (\n",
    "            torch.from_numpy(img0 / 255.0)\n",
    "            .to(dtype=torch.float32, device=device)\n",
    "            .movedim(-1, 0)[None]\n",
    "        )\n",
    "        img1 = (\n",
    "            torch.from_numpy(img1 / 255.0)\n",
    "            .to(dtype=torch.float32, device=device)\n",
    "            .movedim(-1, 0)[None]\n",
    "        )\n",
    "        return model(img0, img1)[0, 0, ..., None].mean().item()\n",
    "\n",
    "    return compute_lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a7cb5-0ac4-4460-9368-e177aa512543",
   "metadata": {},
   "source": [
    "## Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8963f53-7c2e-4ad3-ba8f-69375d868db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [on]\n",
      "Loading model from: /home/hangg/.anaconda3/envs/nerfacc/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "compute_lpips = get_compute_lpips(net=\"vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7c0b35-d919-4c19-9987-fbb06b937b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    \"chair\",\n",
    "    \"drums\",\n",
    "    \"ficus\",\n",
    "    \"hotdog\",\n",
    "    \"lego\",\n",
    "    \"materials\",\n",
    "    \"mic\",\n",
    "    \"ship\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c23b40b-04ea-425e-9a54-35b564b06411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:20<00:00,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotdog 0.028047882309183477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TensoRF\n",
    "for scene in SCENES:\n",
    "    scores = []\n",
    "    for i in tqdm(\n",
    "        range(\n",
    "            len(\n",
    "                [\n",
    "                    p\n",
    "                    for p in glob(\n",
    "                        f\"/shared/hangg/projects/tensorf/data/nerf_synthetic/{scene}/test/*.png\"\n",
    "                    )\n",
    "                    if \"depth\" not in p and \"normal\" not in p\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ):\n",
    "        img = (\n",
    "            cv2.imread(\n",
    "                f\"/shared/hangg/projects/tensorf/data/nerf_synthetic/{scene}/test/r_{i:d}.png\",\n",
    "                flags=cv2.IMREAD_UNCHANGED,\n",
    "            )\n",
    "            / 255.0\n",
    "        )\n",
    "        img = (\n",
    "            (img[..., :3] * img[..., -1:] + 1 - img[..., -1:]) * 255\n",
    "        ).astype(np.uint8)\n",
    "        img = img[..., ::-1]\n",
    "        img_pred = cv2.imread(\n",
    "            f\"/shared/hangg/projects/tensorf/log/tensorf_{scene}_VM_15k_nerfacc/tensorf_{scene}_VM_15k_nerfacc/imgs_test_all/{i:03d}.png\"\n",
    "        )[..., ::-1]\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c5dde-49e6-4ac7-b022-1a6001cfe415",
   "metadata": {},
   "source": [
    "## T&T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2fab1e3-be19-46f4-92db-953f49b96482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [on]\n",
      "Loading model from: /home/hangg/.anaconda3/envs/nerfacc/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "compute_lpips = get_compute_lpips(net=\"vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd86702b-3180-4a2f-8c9b-edca5d367801",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    \"Barn\",\n",
    "    # \"Caterpillar\",\n",
    "    # \"Family\",\n",
    "    # \"Truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be4cfb7b-091b-42c7-8624-1d98defa4194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:13<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barn 0.24504011558989683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TensoRF\n",
    "for scene in SCENES:\n",
    "    scores = []\n",
    "    for i, path in enumerate(\n",
    "        tqdm(\n",
    "            sorted(\n",
    "                glob(\n",
    "                    f\"/shared/hangg/projects/tensorf/data/TanksAndTemple/{scene}/rgb/1_*.png\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ):\n",
    "        img = cv2.imread(path)[..., ::-1]\n",
    "        scene = scene.lower()\n",
    "        img_pred = cv2.imread(\n",
    "            # f\"/shared/hangg/projects/tensorf/log/tensorf_{scene}_VM_15k/tensorf_{scene}_VM_15k/imgs_test_all/{i:03d}.png\"\n",
    "            # f\"/shared/hangg/projects/tensorf/log/tensorf_{scene}_VM_15k_nerfacc/tensorf_{scene}_VM_15k_nerfacc/imgs_test_all/{i:03d}.png\"\n",
    "            f\"/shared/hangg/projects/tensorf/log/tensorf_{scene}_VM_15k_prop/imgs_test_all/{i:03d}.png\"\n",
    "        )[..., ::-1]\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "898ffc2a-d392-4b2f-b918-0556995f3a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/shared/hangg/projects/tensorf/log/tensorf_family_VM_15k_prop/tensorf_family_VM_15k_prop/imgs_test_all/000.png'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"/shared/hangg/projects/tensorf/log/tensorf_{scene}_VM_15k_prop/tensorf_{scene}_VM_15k_prop/imgs_test_all/{i:03d}.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e2706-c0a2-476f-a216-eb9db096b7d1",
   "metadata": {},
   "source": [
    "## Noisy Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "823e6476-4789-4831-a3ea-461b40f50857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [on]\n",
      "Loading model from: /home/hangg/.anaconda3/envs/nerfacc/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "compute_lpips = get_compute_lpips(net=\"alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "452087cd-5dc6-44eb-86e7-2c4f7a6a204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    \"chair\",\n",
    "    \"drums\",\n",
    "    \"ficus\",\n",
    "    \"hotdog\",\n",
    "    \"lego\",\n",
    "    \"materials\",\n",
    "    \"mic\",\n",
    "    \"ship\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fabc4b80-16f4-4503-9f3c-3c3f3cc88557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 51.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair 0.03373537153936922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drums 0.0707241720892489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 45.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ficus 0.034741305522620676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotdog 0.019965999042615295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lego 0.0349097693618387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 41.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "materials 0.029524475745856763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mic 0.03330276141874492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 43.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship 0.09396069411188364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BARF\n",
    "for scene in SCENES:\n",
    "    scores = []\n",
    "    paths = sorted(\n",
    "        glob(\n",
    "            f\"/shared/hangg/projects/barf/output/{scene}/{scene}_nerfacc/test_view/rgb_GT_*.png\"\n",
    "        )\n",
    "    )\n",
    "    pred_paths = [p.replace(\"_GT_\", \"_\") for p in paths]\n",
    "    for path, pred_path in zip(tqdm(paths), pred_paths):\n",
    "        img = (\n",
    "            cv2.imread(\n",
    "                path,\n",
    "                flags=cv2.IMREAD_UNCHANGED,\n",
    "            )\n",
    "        )[..., ::-1]\n",
    "        img_pred = cv2.imread(pred_path)[..., ::-1]\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6d573-55bf-43b3-92fa-c9792b265a4c",
   "metadata": {},
   "source": [
    "## D-NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fba1a2c2-b0ca-4119-8f92-c62193ac3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_lpips = get_compute_lpips(net=\"vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb33c14b-64d9-41cc-bdbe-b077729d39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    \"bouncingballs\",\n",
    "    \"hellwarrior\",\n",
    "    \"hook\",\n",
    "    \"jumpingjacks\",\n",
    "    \"lego\",\n",
    "    \"mutant\",\n",
    "    \"standup\",\n",
    "    \"trex\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34d4312b-7cf9-4b8f-93b6-1befa19e4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bouncingballs 0.027032664604485036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellwarrior 0.06595230624079704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook 0.05704173985868692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumpingjacks 0.0364542349241674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lego 0.10605081543326378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutant 0.04209237983450294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standup 0.025279932329431175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trex 0.053174083679914476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TiNeuVox\n",
    "for scene in SCENES:\n",
    "    scores = []\n",
    "    for i in tqdm(\n",
    "        range(\n",
    "            len(\n",
    "                glob(\n",
    "                    f\"/shared/hangg/projects/tineuvox/data/dnerf/{scene}/test/*.png\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ):\n",
    "        img = (\n",
    "            cv2.imread(\n",
    "                f\"/shared/hangg/projects/tineuvox/data/dnerf/{scene}/test/r_{i:03d}.png\",\n",
    "                flags=cv2.IMREAD_UNCHANGED,\n",
    "            )\n",
    "            / 255.0\n",
    "        )\n",
    "        img = (\n",
    "            (img[..., :3] * img[..., -1:] + 1 - img[..., -1:]) * 255\n",
    "        ).astype(np.uint8)\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            (400, 400),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "        )[..., ::-1]\n",
    "        img_pred = cv2.imread(\n",
    "            # f\"/shared/hangg/projects/tineuvox/logs/nerf_synthetic/small/dnerf_{scene}-400_2/render_test_fine_last/{i:03d}.png\"\n",
    "            f\"/shared/hangg/projects/tineuvox/logs/nerf_synthetic/small/dnerf_{scene}-400/render_test_fine_last/{i:03d}.png\"\n",
    "        )[..., ::-1]\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23ae1382-cd5c-42a2-a402-029e9617f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    # \"bouncingballs\",\n",
    "    # \"hellwarrior\",\n",
    "    # \"hook\",\n",
    "    \"jumpingjacks\",\n",
    "    # \"lego\",\n",
    "    # \"mutant\",\n",
    "    # \"standup\",\n",
    "    # \"trex\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f7db507-f8d9-4a20-8086-ebc0e484a0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumpingjacks 0.041373722814023496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Planes\n",
    "for scene in SCENES:\n",
    "    scores = []\n",
    "    video = media.read_video(\n",
    "        f\"/shared/hangg/projects/kplanes/logs/syntheticdynamic/{scene}_hybrid/step30000.mp4\"\n",
    "    )\n",
    "    imgs = video[:, 800:1600]\n",
    "    img_preds = video[:, :800]\n",
    "    for img, img_pred in zip(tqdm(imgs), img_preds):\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf889b-6d3a-42ad-84fb-8906da9ac373",
   "metadata": {},
   "source": [
    "## HyperNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0468512-6f6a-4ac3-a7e3-77c075a31b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [on]\n",
      "Loading model from: /home/hangg/.anaconda3/envs/nerfacc/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "compute_lpips = get_compute_lpips(net=\"vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "181e27bd-3b58-452d-9848-18613b7a3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [\n",
    "    # \"hypernerf/vrig-3dprinter\",\n",
    "    # \"nerfies/broom\",\n",
    "    # \"hypernerf/vrig-chicken\",\n",
    "    \"hypernerf/vrig-peel-banana\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78d9c2b4-3fd8-4697-979b-03e45bedce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 513/513 [00:31<00:00, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernerf/vrig-peel-banana 0.30839472890016395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TiNeuVox\n",
    "for scene in SCENES:\n",
    "    with open(\n",
    "        f\"/shared/hangg/projects/tineuvox/data/{scene}/dataset.json\"\n",
    "    ) as f:\n",
    "        test_names = json.load(f)[\"val_ids\"]\n",
    "    scores = []\n",
    "    for i, test_name in enumerate(tqdm(test_names)):\n",
    "        img = cv2.imread(\n",
    "            f\"/shared/hangg/projects/tineuvox/data/{scene}/rgb/2x/{test_name}.png\",\n",
    "            flags=cv2.IMREAD_UNCHANGED,\n",
    "        )[..., ::-1]\n",
    "        scene_suffix = scene.split(\"/\")[-1].removeprefix(\"vrig-\")\n",
    "        img_pred = cv2.imread(\n",
    "            f\"/shared/hangg/projects/tineuvox/logs/vrig_data/vrig/base-{scene_suffix}_3/render_test_fine_last/{i:03d}.png\"\n",
    "        )[..., ::-1]\n",
    "        scores.append(compute_lpips(img, img_pred))\n",
    "    print(scene, np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfacc",
   "language": "python",
   "name": "nerfacc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
